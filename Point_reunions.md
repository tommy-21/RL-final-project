# RL-final-project
Projet final de Reinforcement Learning

## Point des informations donnn√©es par le prof


### Interface utilisateur
* Attendus :
    - Une fen√™tre repr√©sentant l'interface, avec un chemin (un d√©part et une arriv√©e)
    - Deux modes : Manuel et Automatique et si possible un troisi√®me (Semi-Automatique)
* Utiliser pygame si nous n'avons jamais cod√© un jeu auparavant

### Algorithmes
Plusieurs cas sont √† distinguer :
* Cas discret : l'espace d'√©tat (les coordonn√©es x et y de la voiture) est discret ; l'algo Q-learning. 
* Cas continu : l'espace d'√©tat est continu ; l'algo : Q-Learning adapt√© ou QNN

### Donn√©es d'entrainement
A simuler selon le cas (discret ou continu) et nos variables 

## Point de la rencontre du jeudi 14/03/2024
Nous avons choisi de faire le cas continu pour l'instant. 
 
- ‚≠ê Etats $S_t$ (variables d√©finissant l'√©tat) 
    * position : x, y
    * vitesse : v 
    * Orientation : $\theta$ (angle par rapport √† une r√©f√©rence)
    * Obstacles : pas encore concr√®tement d√©finis

- ü¶æ Actions $A_t$ (vu comme les actions possibles √† l'utilisateur)
    * Acc√©l√©rer ‚è´
    * Ralentir üîº
    * Reculer ‚è¨
    * Tourner √† gauche ‚¨ÖÔ∏è
    * Tourner √† droite ‚û°Ô∏è

- üåü Nouvel √©tat $S_{t+1}$ : Le nouvel √©tat sera calcul√© par une fonction g √† partir de l'√©tat actuel et de l'action effectu√©e telle que : $$S_{t+1} = g(S_t, A_t)$$
  
- üí∞ R√©compenses
    * Sort de la route : -(??)
    * Cogne obstacle : -(??)
    * Atteint l'arriv√©e : +(??)
    * Respecte pas le code de la route : -(??)

- ‚ùì Probl√©matiques ouvertes
    * Compr√©hension de l'adaptation de l'algo Q-Learning et l'impl√©mentation des r√©seaux de neurones QNN
    * Comment va se faire la simulation des donn√©es ?
    * D√©finition de la fonction $g$
    * Prise en main de pygame
    * Formalisation des obstables (variable d'√©tat)
    * Semi-discret ou continu ? la question reste ouverte (surtout en ce qui concerne le temps aussi) 
    * Vitesse maximale ind√©passable ou p√©nalisante ?
